(*Rasmus s164162, Solvi s174391, Muse s194615*)

// The generated lexer module will start with this code
{
module GCL1Lexer
open FSharp.Text.Lexing
// open the module that defines the tokens
open GCL1Parser
}

//Macros
let digit       = ['0'-'9']
let num         = digit+
let whitespace  = [' ' '\u00A0' '\r' '\n' '\t']+
let alfabet     = ['A'-'Z''a'-'z']
let var         = ['a' - 'z''A' - 'Z']['a' - 'z''A' - 'Z''_''0' - '9']* //alfabet(alfabet|digit)*

//Tokens
rule tokenize = parse
| whitespace        { tokenize lexbuf}

//Arithmetics
| '*'                      { TIMES }
| '/'                      { DIV }
| '+'                      { PLUS }
| '-'                      { MINUS }
| '^'                      { POW }
| "-"                      { UNARY }

//Parenthesis
| '('                      { LPAR }
| ')'                      { RPAR }

//Boolean
| "true"                   { TRUE }
| "false"                  { FALSE }
| "||"                     { SOR }
| "&&"                     { SAND }
| "!="                     { NEQ }
| "<="                     { LTE }
| ">="                     { GTE }
| '&'                      { AND }
| '|'                      { OR }
| '!'                      { NOT }
| '='                      { EQ }
| '>'                      { GT }
| '<'                      { LT }

//GC
| "->"                     { ARR }
| "[]"                     { SB }


//COMMAND
| ';'                      { SC }
| ":="                     { ASS }
| "if" whitespace          { IF }
| whitespace"fi"           { FI }
| "do" whitespace          { DO }
| whitespace "od"          { OD }
| "skip"                   { SKIP }

//NUM & VAR
| num                      { NUM(Double.Parse(LexBuffer<_>.LexemeString lexbuf))}
| var                      { VAR(string(LexBuffer<_>.LexemeString lexbuf)) }

//EOF
| eof                      { EOF }